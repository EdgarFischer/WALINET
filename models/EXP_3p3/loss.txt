Epoch; Epoch Loss; Validation Loss; Learning Rate; 
Epoch: 001, Loss: 0.0000002508, Val Loss: 0.0000002732, LR: 0.0010000000, best model
Epoch: 002, Loss: 0.0000002397, Val Loss: 0.0000002529, LR: 0.0010000000, best model
Epoch: 003, Loss: 0.0000002385, Val Loss: 0.0000002477, LR: 0.0010000000, best model
Epoch: 004, Loss: 0.0000002363, Val Loss: 0.0000002534, LR: 0.0010000000
Epoch: 005, Loss: 0.0000002347, Val Loss: 0.0000002455, LR: 0.0010000000, best model
Epoch: 006, Loss: 0.0000002329, Val Loss: 0.0000002444, LR: 0.0010000000, best model
Epoch: 007, Loss: 0.0000002322, Val Loss: 0.0000002452, LR: 0.0010000000
Epoch: 008, Loss: 0.0000002313, Val Loss: 0.0000002467, LR: 0.0010000000
Epoch: 009, Loss: 0.0000002306, Val Loss: 0.0000002524, LR: 0.0010000000
Epoch: 010, Loss: 0.0000002302, Val Loss: 0.0000002449, LR: 0.0010000000
Epoch: 011, Loss: 0.0000002292, Val Loss: 0.0000002558, LR: 0.0010000000
Epoch: 012, Loss: 0.0000002280, Val Loss: 0.0000002378, LR: 0.0010000000, best model
Epoch: 013, Loss: 0.0000002283, Val Loss: 0.0000002388, LR: 0.0010000000
Epoch: 014, Loss: 0.0000002265, Val Loss: 0.0000002395, LR: 0.0010000000
Epoch: 015, Loss: 0.0000002266, Val Loss: 0.0000002422, LR: 0.0010000000
Epoch: 016, Loss: 0.0000002265, Val Loss: 0.0000002557, LR: 0.0010000000
Epoch: 017, Loss: 0.0000002248, Val Loss: 0.0000002355, LR: 0.0010000000, best model
Epoch: 018, Loss: 0.0000002256, Val Loss: 0.0000002404, LR: 0.0010000000
Epoch: 019, Loss: 0.0000002247, Val Loss: 0.0000002351, LR: 0.0010000000, best model
Epoch: 020, Loss: 0.0000002244, Val Loss: 0.0000002339, LR: 0.0010000000, best model
Epoch: 021, Loss: 0.0000002231, Val Loss: 0.0000002361, LR: 0.0010000000
Epoch: 022, Loss: 0.0000002229, Val Loss: 0.0000002483, LR: 0.0010000000
Epoch: 023, Loss: 0.0000002228, Val Loss: 0.0000002311, LR: 0.0010000000, best model
Epoch: 024, Loss: 0.0000002233, Val Loss: 0.0000002468, LR: 0.0010000000
Epoch: 025, Loss: 0.0000002225, Val Loss: 0.0000002447, LR: 0.0010000000
Epoch: 026, Loss: 0.0000002222, Val Loss: 0.0000002331, LR: 0.0010000000
Epoch: 027, Loss: 0.0000002214, Val Loss: 0.0000002328, LR: 0.0010000000
Epoch: 028, Loss: 0.0000002211, Val Loss: 0.0000002443, LR: 0.0010000000
Epoch: 029, Loss: 0.0000002208, Val Loss: 0.0000002261, LR: 0.0010000000, best model
Epoch: 030, Loss: 0.0000002198, Val Loss: 0.0000002339, LR: 0.0010000000
Epoch: 031, Loss: 0.0000002197, Val Loss: 0.0000002352, LR: 0.0010000000
Epoch: 032, Loss: 0.0000002194, Val Loss: 0.0000002320, LR: 0.0010000000
Epoch: 033, Loss: 0.0000002192, Val Loss: 0.0000002310, LR: 0.0010000000
Epoch: 034, Loss: 0.0000002189, Val Loss: 0.0000002348, LR: 0.0010000000
Epoch: 035, Loss: 0.0000002190, Val Loss: 0.0000002316, LR: 0.0010000000
Epoch: 036, Loss: 0.0000002187, Val Loss: 0.0000002347, LR: 0.0010000000
Epoch: 037, Loss: 0.0000002182, Val Loss: 0.0000002382, LR: 0.0010000000
Epoch: 038, Loss: 0.0000002193, Val Loss: 0.0000002405, LR: 0.0010000000
Epoch: 039, Loss: 0.0000002176, Val Loss: 0.0000002265, LR: 0.0010000000
Epoch: 040, Loss: 0.0000002179, Val Loss: 0.0000002304, LR: 0.0010000000
Epoch: 041, Loss: 0.0000002167, Val Loss: 0.0000002278, LR: 0.0010000000
Epoch: 042, Loss: 0.0000002166, Val Loss: 0.0000002326, LR: 0.0010000000
Epoch: 043, Loss: 0.0000002166, Val Loss: 0.0000002289, LR: 0.0010000000
Epoch: 044, Loss: 0.0000002166, Val Loss: 0.0000002275, LR: 0.0010000000
Epoch: 045, Loss: 0.0000002159, Val Loss: 0.0000002244, LR: 0.0010000000, best model
Epoch: 046, Loss: 0.0000002148, Val Loss: 0.0000002274, LR: 0.0010000000
Epoch: 047, Loss: 0.0000002157, Val Loss: 0.0000002280, LR: 0.0010000000
Epoch: 048, Loss: 0.0000002157, Val Loss: 0.0000002337, LR: 0.0010000000
Epoch: 049, Loss: 0.0000002155, Val Loss: 0.0000002245, LR: 0.0010000000
Epoch: 050, Loss: 0.0000002156, Val Loss: 0.0000002374, LR: 0.0010000000
Epoch: 051, Loss: 0.0000002156, Val Loss: 0.0000002252, LR: 0.0010000000
Epoch: 052, Loss: 0.0000002142, Val Loss: 0.0000002269, LR: 0.0010000000
