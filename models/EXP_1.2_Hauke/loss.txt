Epoch; Epoch Loss; Validation Loss; Learning Rate; 
Epoch: 001, Loss: 0.0000003776, Val Loss: 0.0000002906, LR: 0.0010000000, best model
Epoch: 002, Loss: 0.0000002639, Val Loss: 0.0000002861, LR: 0.0010000000, best model
Epoch: 003, Loss: 0.0000002623, Val Loss: 0.0000002890, LR: 0.0010000000
Epoch: 004, Loss: 0.0000002592, Val Loss: 0.0000002795, LR: 0.0010000000, best model
Epoch: 005, Loss: 0.0000002610, Val Loss: 0.0000002757, LR: 0.0010000000, best model
Epoch: 006, Loss: 0.0000002581, Val Loss: 0.0000002738, LR: 0.0010000000, best model
Epoch: 007, Loss: 0.0000002611, Val Loss: 0.0000002728, LR: 0.0010000000, best model
Epoch: 008, Loss: 0.0000002605, Val Loss: 0.0000002887, LR: 0.0010000000
Epoch: 009, Loss: 0.0000002584, Val Loss: 0.0000002749, LR: 0.0010000000
Epoch: 010, Loss: 0.0000002587, Val Loss: 0.0000002751, LR: 0.0010000000
Epoch: 011, Loss: 0.0000002592, Val Loss: 0.0000002737, LR: 0.0010000000
Epoch: 012, Loss: 0.0000002588, Val Loss: 0.0000002771, LR: 0.0010000000
Epoch: 013, Loss: 0.0000002593, Val Loss: 0.0000002815, LR: 0.0010000000
Epoch: 014, Loss: 0.0000002591, Val Loss: 0.0000002753, LR: 0.0010000000
Epoch: 015, Loss: 0.0000002588, Val Loss: 0.0000003018, LR: 0.0010000000
Epoch: 016, Loss: 0.0000002583, Val Loss: 0.0000002903, LR: 0.0010000000
Epoch: 017, Loss: 0.0000002577, Val Loss: 0.0000002742, LR: 0.0010000000
Epoch: 018, Loss: 0.0000002583, Val Loss: 0.0000002748, LR: 0.0010000000
Epoch: 019, Loss: 0.0000002574, Val Loss: 0.0000002829, LR: 0.0010000000
Epoch: 020, Loss: 0.0000002589, Val Loss: 0.0000002716, LR: 0.0010000000, best model
Epoch: 021, Loss: 0.0000002575, Val Loss: 0.0000002757, LR: 0.0010000000
Epoch: 022, Loss: 0.0000002574, Val Loss: 0.0000002890, LR: 0.0010000000
Epoch: 023, Loss: 0.0000002581, Val Loss: 0.0000002886, LR: 0.0010000000
Epoch: 024, Loss: 0.0000002573, Val Loss: 0.0000002733, LR: 0.0010000000
Epoch: 025, Loss: 0.0000002580, Val Loss: 0.0000002744, LR: 0.0010000000
Epoch: 026, Loss: 0.0000002560, Val Loss: 0.0000002747, LR: 0.0010000000
Epoch: 027, Loss: 0.0000002568, Val Loss: 0.0000002756, LR: 0.0010000000
Epoch: 028, Loss: 0.0000002573, Val Loss: 0.0000002761, LR: 0.0010000000
Epoch: 029, Loss: 0.0000002549, Val Loss: 0.0000002681, LR: 0.0010000000, best model
Epoch: 030, Loss: 0.0000002566, Val Loss: 0.0000002773, LR: 0.0010000000
Epoch: 031, Loss: 0.0000002570, Val Loss: 0.0000002791, LR: 0.0010000000
Epoch: 032, Loss: 0.0000002562, Val Loss: 0.0000002692, LR: 0.0010000000
Epoch: 033, Loss: 0.0000002561, Val Loss: 0.0000002709, LR: 0.0010000000
Epoch: 034, Loss: 0.0000002568, Val Loss: 0.0000002832, LR: 0.0010000000
Epoch: 035, Loss: 0.0000002549, Val Loss: 0.0000002708, LR: 0.0010000000
Epoch: 036, Loss: 0.0000002567, Val Loss: 0.0000002697, LR: 0.0010000000
Epoch: 037, Loss: 0.0000002572, Val Loss: 0.0000002825, LR: 0.0010000000
Epoch: 038, Loss: 0.0000002544, Val Loss: 0.0000002842, LR: 0.0010000000
Epoch: 039, Loss: 0.0000002545, Val Loss: 0.0000002741, LR: 0.0010000000
Epoch: 040, Loss: 0.0000002541, Val Loss: 0.0000002923, LR: 0.0010000000
Epoch: 041, Loss: 0.0000002548, Val Loss: 0.0000002692, LR: 0.0010000000
Epoch: 042, Loss: 0.0000002543, Val Loss: 0.0000002697, LR: 0.0010000000
Epoch: 043, Loss: 0.0000002555, Val Loss: 0.0000002698, LR: 0.0010000000
Epoch: 044, Loss: 0.0000002528, Val Loss: 0.0000002690, LR: 0.0010000000
Epoch: 045, Loss: 0.0000002549, Val Loss: 0.0000002743, LR: 0.0010000000
Epoch: 046, Loss: 0.0000002544, Val Loss: 0.0000002672, LR: 0.0010000000, best model
Epoch: 047, Loss: 0.0000002553, Val Loss: 0.0000002765, LR: 0.0010000000
Epoch: 048, Loss: 0.0000002544, Val Loss: 0.0000002646, LR: 0.0010000000, best model
Epoch: 049, Loss: 0.0000002539, Val Loss: 0.0000002675, LR: 0.0010000000
Epoch: 050, Loss: 0.0000002525, Val Loss: 0.0000002800, LR: 0.0010000000
Epoch: 051, Loss: 0.0000002551, Val Loss: 0.0000002718, LR: 0.0010000000
Epoch: 052, Loss: 0.0000002543, Val Loss: 0.0000002817, LR: 0.0010000000
Epoch: 053, Loss: 0.0000002532, Val Loss: 0.0000002687, LR: 0.0010000000
Epoch: 054, Loss: 0.0000002546, Val Loss: 0.0000002804, LR: 0.0010000000
Epoch: 055, Loss: 0.0000002544, Val Loss: 0.0000002929, LR: 0.0010000000
Epoch: 056, Loss: 0.0000002525, Val Loss: 0.0000002835, LR: 0.0010000000
Epoch: 057, Loss: 0.0000002523, Val Loss: 0.0000002669, LR: 0.0010000000
Epoch: 058, Loss: 0.0000002524, Val Loss: 0.0000002729, LR: 0.0010000000
Epoch: 059, Loss: 0.0000002540, Val Loss: 0.0000002736, LR: 0.0010000000
Epoch: 060, Loss: 0.0000002523, Val Loss: 0.0000002791, LR: 0.0010000000
Epoch: 061, Loss: 0.0000002521, Val Loss: 0.0000002680, LR: 0.0010000000
Epoch: 062, Loss: 0.0000002516, Val Loss: 0.0000002813, LR: 0.0010000000
Epoch: 063, Loss: 0.0000002518, Val Loss: 0.0000002674, LR: 0.0010000000
Epoch: 064, Loss: 0.0000002519, Val Loss: 0.0000002747, LR: 0.0010000000
Epoch: 065, Loss: 0.0000002517, Val Loss: 0.0000002654, LR: 0.0010000000
Epoch: 066, Loss: 0.0000002530, Val Loss: 0.0000002725, LR: 0.0010000000
Epoch: 067, Loss: 0.0000002532, Val Loss: 0.0000002694, LR: 0.0010000000
Epoch: 068, Loss: 0.0000002512, Val Loss: 0.0000002682, LR: 0.0010000000
Epoch: 069, Loss: 0.0000002506, Val Loss: 0.0000002671, LR: 0.0010000000
Epoch: 070, Loss: 0.0000002498, Val Loss: 0.0000002670, LR: 0.0010000000
Epoch: 071, Loss: 0.0000002518, Val Loss: 0.0000002809, LR: 0.0010000000
Epoch: 072, Loss: 0.0000002512, Val Loss: 0.0000002673, LR: 0.0010000000
Epoch: 073, Loss: 0.0000002509, Val Loss: 0.0000002706, LR: 0.0010000000
Epoch: 074, Loss: 0.0000002505, Val Loss: 0.0000002708, LR: 0.0010000000
Epoch: 075, Loss: 0.0000002517, Val Loss: 0.0000002751, LR: 0.0010000000
Epoch: 076, Loss: 0.0000002503, Val Loss: 0.0000002710, LR: 0.0010000000
Epoch: 077, Loss: 0.0000002503, Val Loss: 0.0000002645, LR: 0.0010000000, best model
Epoch: 078, Loss: 0.0000002504, Val Loss: 0.0000002631, LR: 0.0010000000, best model
Epoch: 079, Loss: 0.0000002487, Val Loss: 0.0000002968, LR: 0.0010000000
Epoch: 080, Loss: 0.0000002506, Val Loss: 0.0000002740, LR: 0.0010000000
Epoch: 081, Loss: 0.0000002509, Val Loss: 0.0000002640, LR: 0.0010000000
