{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a988357e",
   "metadata": {},
   "source": [
    "In this file I start by implementing a compressed sensing reconstruction approach. I want to have a well accepted classical method \n",
    "as a baseline for my later deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0331826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "sys.path.append('../models')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1' #, this way I would choose GPU 3 to do the work\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom # for compressing images / only for testing purposes to speed up NN training\n",
    "from scipy.fft import fft2, fftshift\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from scipy.io import savemat\n",
    "import nibabel as nib\n",
    "import h5py\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcb49e",
   "metadata": {},
   "source": [
    "# Check Masks for nans and infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Vol in range(5,10):\n",
    "    brain_mask = np.load(f'Vol{Vol}/masks/brain_mask.npy')\n",
    "    lipid_mask = np.load(f'Vol{Vol}/masks/lipid_mask.npy')\n",
    "\n",
    "    print('Volume')\n",
    "    print(Vol)\n",
    "    print('Brainmask:')\n",
    "    has_nonfinite = ~np.isfinite(brain_mask).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    print('LipidMask:')\n",
    "    has_nonfinite = ~np.isfinite(lipid_mask).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ffda7",
   "metadata": {},
   "source": [
    "# check original data for nans and infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Vol in range(5,10):\n",
    "\n",
    "    data = np.load(f'Vol{Vol}/OriginalData/data.npy')\n",
    "    IsolatedWater = np.load(f'Vol{Vol}/OriginalData/IsolatedWater.npy')\n",
    "    SupressedWater = np.load(f'Vol{Vol}/OriginalData/SupressedWater.npy')\n",
    "\n",
    "    print('Volume')\n",
    "    print(Vol)\n",
    "    print('data:')\n",
    "    has_nonfinite = ~np.isfinite(data).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    print('IsolatedWater:')\n",
    "    has_nonfinite = ~np.isfinite(IsolatedWater).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    print('SupressedWater:')\n",
    "    has_nonfinite = ~np.isfinite(SupressedWater).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1a54e",
   "metadata": {},
   "source": [
    "# Check Simulations for nans and infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Vol in range(5,10):\n",
    "    with h5py.File(f'Vol{Vol}/TrainData/TrainData_v_1.0.h5', 'r') as f:\n",
    "        # List all top-level groups/datasets\n",
    "        print('Vol', Vol)\n",
    "        print(\"Keys:\", list(f.keys()))\n",
    "        lipid = f['lipid'][:]\n",
    "\n",
    "        has_nonfinite = ~np.isfinite(lipid).all()\n",
    "        print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "        lipid_proj = f['lipid_proj'][:]\n",
    "\n",
    "        has_nonfinite = ~np.isfinite(lipid_proj).all()\n",
    "        print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "        \n",
    "        lipid_projOP = f['lipid_projOP'][:]\n",
    "\n",
    "        has_nonfinite = ~np.isfinite(lipid_projOP).all()\n",
    "        print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "        metab = f['metab'][:]\n",
    "\n",
    "        has_nonfinite = ~np.isfinite(metab).all()\n",
    "        print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "        spectra = f['spectra'][:]\n",
    "        has_nonfinite = ~np.isfinite(spectra).all()\n",
    "        print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "        water = f['water'][:]\n",
    "        has_nonfinite = ~np.isfinite(water).all()\n",
    "        print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212af1b",
   "metadata": {},
   "source": [
    "# Data set 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vol = 5\n",
    "\n",
    "brain_mask = np.load(f'Vol{Vol}/masks/brain_mask.npy')\n",
    "lipid_mask = np.load(f'Vol{Vol}/masks/lipid_mask.npy')\n",
    "\n",
    "data = np.load(f'Vol{Vol}/OriginalData/data.npy')\n",
    "IsolatedWater = np.load(f'Vol{Vol}/OriginalData/IsolatedWater.npy')\n",
    "SupressedWater = np.load(f'Vol{Vol}/OriginalData/SupressedWater.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfd295",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'Vol9/TrainData/TrainData_v_1.1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Vol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVol\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mVol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/TrainData/TrainData_v_1.1.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# List all top-level groups/datasets\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVol\u001b[39m\u001b[38;5;124m'\u001b[39m, Vol)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(f\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'Vol9/TrainData/TrainData_v_1.1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "Vol = 9\n",
    "with h5py.File(f'Vol{Vol}/TrainData/TrainData_v_1.0.h5', 'r') as f:\n",
    "    # List all top-level groups/datasets\n",
    "    print('Vol', Vol)\n",
    "    print(\"Keys:\", list(f.keys()))\n",
    "    lipid = f['lipid'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(lipid).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    lipid_proj = f['lipid_proj'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(lipid_proj).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "    \n",
    "    lipid_projOP = f['lipid_projOP'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(lipid_projOP).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    metab = f['metab'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(metab).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    spectra = f['spectra'][:]\n",
    "    has_nonfinite = ~np.isfinite(spectra).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    water = f['water'][:]\n",
    "    has_nonfinite = ~np.isfinite(water).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951de623",
   "metadata": {},
   "source": [
    "# Remove NANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432dc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume\n",
      "3_Brisbane\n",
      "Brainmask:\n",
      "Contains NaN or Inf? False\n",
      "LipidMask:\n",
      "Contains NaN or Inf? False\n",
      "Volume\n",
      "3_Brisbane\n",
      "data:\n",
      "Contains NaN or Inf? False\n",
      "IsolatedWater:\n",
      "Contains NaN or Inf? False\n",
      "SupressedWater:\n",
      "Contains NaN or Inf? False\n",
      "Vol 3_Brisbane\n",
      "Keys: ['lipid', 'lipid_proj', 'lipid_projOP', 'metab', 'spectra', 'water']\n",
      "Contains NaN or Inf? False\n",
      "Contains NaN or Inf? False\n",
      "Contains NaN or Inf? False\n",
      "Contains NaN or Inf? False\n",
      "Contains NaN or Inf? False\n",
      "Contains NaN or Inf? False\n"
     ]
    }
   ],
   "source": [
    "Vol = '3_Brisbane'\n",
    "\n",
    "brain_mask = np.load(f'Vol{Vol}/masks/brain_mask.npy')\n",
    "lipid_mask = np.load(f'Vol{Vol}/masks/lipid_mask.npy')\n",
    "\n",
    "print('Volume')\n",
    "print(Vol)\n",
    "print('Brainmask:')\n",
    "has_nonfinite = ~np.isfinite(brain_mask).all()\n",
    "print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "print('LipidMask:')\n",
    "has_nonfinite = ~np.isfinite(lipid_mask).all()\n",
    "print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "data = np.load(f'Vol{Vol}/OriginalData/data.npy')\n",
    "IsolatedWater = np.load(f'Vol{Vol}/OriginalData/IsolatedWater.npy')\n",
    "SupressedWater = np.load(f'Vol{Vol}/OriginalData/SupressedWater.npy')\n",
    "\n",
    "print('Volume')\n",
    "print(Vol)\n",
    "print('data:')\n",
    "has_nonfinite = ~np.isfinite(data).all()\n",
    "print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "print('IsolatedWater:')\n",
    "has_nonfinite = ~np.isfinite(IsolatedWater).all()\n",
    "print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "print('SupressedWater:')\n",
    "has_nonfinite = ~np.isfinite(SupressedWater).all()\n",
    "print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "with h5py.File(f'Vol{Vol}/TrainData/TrainData_v_1.1.h5', 'r') as f:\n",
    "    # List all top-level groups/datasets\n",
    "    print('Vol', Vol)\n",
    "    print(\"Keys:\", list(f.keys()))\n",
    "    lipid = f['lipid'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(lipid).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    lipid_proj = f['lipid_proj'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(lipid_proj).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "    \n",
    "    lipid_projOP = f['lipid_projOP'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(lipid_projOP).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    metab = f['metab'][:]\n",
    "\n",
    "    has_nonfinite = ~np.isfinite(metab).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    spectra = f['spectra'][:]\n",
    "    has_nonfinite = ~np.isfinite(spectra).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True\n",
    "\n",
    "    water = f['water'][:]\n",
    "    has_nonfinite = ~np.isfinite(water).all()\n",
    "    print(\"Contains NaN or Inf?\", has_nonfinite)  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc997eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found NaNs in 0 unique rows.\n",
      "Found NaNs in 0 unique rows.\n",
      "Found NaNs in 0 unique rows.\n"
     ]
    }
   ],
   "source": [
    "def summarize_nans_by_first_index(arr):\n",
    "    nan_mask = np.isnan(arr)\n",
    "    nan_indices = np.argwhere(nan_mask)\n",
    "\n",
    "    # Count how many times each first index (row) appears\n",
    "    unique_rows, counts = np.unique(nan_indices[:, 0], return_counts=True)\n",
    "\n",
    "    print(f\"Found NaNs in {len(unique_rows)} unique rows.\")\n",
    "    for i, count in zip(unique_rows, counts):\n",
    "        print(f\"Row {i}: {count} NaNs\")\n",
    "\n",
    "summarize_nans_by_first_index(lipid_proj)  # or whichever array\n",
    "summarize_nans_by_first_index(spectra)  # or whichever array\n",
    "summarize_nans_by_first_index(water)  # or whichever array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "Vol   = '3_Brisbane'\n",
    "base  = f'Vol{Vol}/TrainData'\n",
    "src   = os.path.join(base, 'TrainData_v_1.0.h5')\n",
    "dst   = os.path.join(base, 'TrainData_v_1.1.h5')   # <- new clean file\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Identify corrupt rows from an already-contaminated dataset\n",
    "# ------------------------------------------------------------------\n",
    "with h5py.File(src, 'r') as f:\n",
    "    spectra = f['spectra'][...]                 # load once, file still open\n",
    "bad_rows   = np.unique(np.argwhere(~np.isfinite(spectra))[:, 0])\n",
    "keep_mask  = ~np.isin(np.arange(spectra.shape[0]), bad_rows)\n",
    "print(f'Bad rows  : {bad_rows.tolist()}')\n",
    "print(f'Rows kept : {keep_mask.sum()} of {spectra.shape[0]}')\n",
    "\n",
    "# Which datasets should be trimmed?\n",
    "datasets_to_clean = {'lipid', 'lipid_proj', 'metab', 'spectra', 'water'}\n",
    "# lipid_projOP stays as-is\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Copy & clean in one pass\n",
    "# ------------------------------------------------------------------\n",
    "with h5py.File(src, 'r') as fin, h5py.File(dst, 'w') as fout:\n",
    "    for k in fin.keys():\n",
    "        data = fin[k][...]\n",
    "        if k in datasets_to_clean:\n",
    "            data = data[keep_mask]              # drop corrupt rows\n",
    "        fout.create_dataset(k, data=data, compression='gzip')\n",
    "\n",
    "print('✅  Clean file written to', dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8a485",
   "metadata": {},
   "source": [
    "# Compute average projection operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "version = 'v_1.0'\n",
    "subjects = [6, 7, 8, 9]  # die Vol-Nummern\n",
    "\n",
    "operators = []\n",
    "for sub in subjects:\n",
    "    file_path = f'Vol{sub}/TrainData/TrainData_{version}.h5'\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        operators.append(f['lipid_projOP'][:])\n",
    "\n",
    "# Stacken und Mittelwert über das 0. Axis nehmen\n",
    "lipid_projOP_avg = np.mean(np.stack(operators, axis=0), axis=0)\n",
    "\n",
    "print(\"Shape lipid_projOP_avg:\", lipid_projOP_avg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f7dbd3",
   "metadata": {},
   "source": [
    "Now saved data sets based on average operator above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Vol in range(5,10):\n",
    "\n",
    "#     version = 'v_1.0'\n",
    "#     in_path  = f'Vol{Vol}/TrainData/TrainData_{version}.h5'\n",
    "#     out_path = f'Vol{Vol}/TrainData/TrainData_{version}_averaged.h5'\n",
    "\n",
    "#     # --- Angenommen: lipid_projOP_avg ist schon berechnet ---\n",
    "#     # z.B. aus subjects = [6,7,8,9] und\n",
    "#     # lipid_projOP_avg = np.mean(np.stack(operators, axis=0), axis=0)\n",
    "\n",
    "#     # 1) Alte Daten laden\n",
    "#     with h5py.File(in_path, 'r') as f:\n",
    "#         metab   = f['metab'][:]\n",
    "#         water   = f['water'][:]\n",
    "#         spectra = f['spectra'][:]\n",
    "#         lipid   = f['lipid'][:]\n",
    "\n",
    "#     # 2) Neuen Lipid-Projektionsanteil berechnen\n",
    "#     lipid_proj_new = np.matmul(spectra, lipid_projOP_avg)\n",
    "\n",
    "#     # 3) Alles in neue Datei schreiben\n",
    "#     with h5py.File(out_path, 'w') as hf:\n",
    "#         hf.create_dataset('metab',       data=metab)\n",
    "#         hf.create_dataset('water',       data=water)\n",
    "#         hf.create_dataset('spectra',     data=spectra)\n",
    "#         hf.create_dataset('lipid',       data=lipid)\n",
    "#         hf.create_dataset('lipid_proj',  data=lipid_proj_new)\n",
    "#         hf.create_dataset('lipid_projOP',data=lipid_projOP_avg)\n",
    "\n",
    "#     print(f'Neue Datei geschrieben: {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2f70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
